#!/usr/bin/env bash

exec 1>&2
onlinepasses=$1
batchpasses=$2
regularization=$3
nbits=$4
termination=$5
uniqId=$6

export 1>&2

uniqId=`expr $uniqId \* 2`;

echo "[train_click_prediction_mapper] ./vw -b $nbits --initial_weight 0.000000000000001 --total $mapreduce_job_maps --node $mapred_task_partition --unique_id $uniqId --cache_file temp.cache --passes $batchpasses --l2 $regularization -d /dev/stdin -f model  --span_server $mapreduce_job_submithostaddress --bfgs --mem 10 --loss_function logistic --readable_model model.readable  --termination $termination 2>&1 | tee output_bfgs >/dev/stderr"

chmod +x ./vw

./vw -b $nbits --initial_weight 0.000000000000001 --total $mapreduce_job_maps --node $mapred_task_partition --unique_id $uniqId --cache_file temp.cache --passes $batchpasses --l2 $regularization -d /dev/stdin -f model  --span_server $mapreduce_job_submithostaddress --bfgs --mem 10 --loss_function logistic --readable_model model.readable  --termination $termination 2>&1 | tee output_bfgs >/dev/stderr


mapred_output_dir=$mapreduce_output_fileoutputformat_outputdir

HADOOP_HOME=/home/gs/hadoop/current/

ls -l;

if [ "$mapred_task_partition" == '0' ]
then
    tar cvf model.tar model* >/dev/stderr
    $HADOOP_HOME/bin/hadoop fs -rmr $mapred_output_dir/model*
    $HADOOP_HOME/bin/hadoop fs -rmr $mapred_output_dir/output*
    $HADOOP_HOME/bin/hadoop fs -put model.tar output_* $mapred_output_dir
fi
